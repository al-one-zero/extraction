{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "data = pd.read_pickle(\"../data/df_preproc.pk\")\n",
    "hashtags_vocab = reduce((lambda x, y: set(x).union(y)), data.Hashtags)\n",
    "mentions_vocab = reduce((lambda x, y: set(x).union(y)), data.Mentions)\n",
    "\n",
    "_embed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Avis Entreprise                                              Tweet  \\\n",
      "0000  neu        apl                20 min line apple store short pump.   \n",
      "0001  irr        msf  Nueva tecnologÃ­a convierte cualquier superfici...   \n",
      "0002  neu        ggl  Some people should not post replies in Google+...   \n",
      "0003  neg        apl  I know a few others having same issue RT Joelp...   \n",
      "0004  neg        msf  Microsoft - We put the \"\"backwards\"\" into back...   \n",
      "...   ...        ...                                                ...   \n",
      "4168  neg        apl  fuck this see you hoes  work WeakTwip Munnns a...   \n",
      "4169  neg        msf  Microsoft, Adobe lose $13.5bn to piracy: Repor...   \n",
      "4170  neu        twt  I tried to explain why you would do \"\"The Twit...   \n",
      "4171  neg        apl  Installed io5 - fine on ipad but wiped wife's ...   \n",
      "4172  neg        msf  microsoft careers site is giving errors for an...   \n",
      "\n",
      "                            Hashtags                   Mentions Language  \\\n",
      "0000                              []             [apple, short]       en   \n",
      "0001          [Microsoft, omnitouch]                         []       es   \n",
      "0002                       [Google+]                         []       en   \n",
      "0003                              []         [Joelplane, Apple]       en   \n",
      "0004  [Microsoft, instantfollowback]                         []       en   \n",
      "...                              ...                        ...      ...   \n",
      "4168                              []  [WeakTwip, Munnns, APPLE]       en   \n",
      "4169              [Microsoft, Adobe]                         []       en   \n",
      "4170           [Twitter, 8220, 8221]           [jefferypjacobs]       en   \n",
      "4171              [Bigtrouble, help]                    [apple]       en   \n",
      "4172     [microsoft, careers, weird]                         []       en   \n",
      "\n",
      "      LanguageProbability  \n",
      "0000             0.670655  \n",
      "0001             0.876679  \n",
      "0002             0.989970  \n",
      "0003             0.973644  \n",
      "0004             0.835478  \n",
      "...                   ...  \n",
      "4168             0.604537  \n",
      "4169             0.714877  \n",
      "4170             0.837970  \n",
      "4171             0.898683  \n",
      "4172             0.694426  \n",
      "\n",
      "[4173 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Op type not registered 'SentencepieceOp' in binary running on alones-MacBook-Pro.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n If trying to load on a different device from the computational device, consider using setting the `experimental_io_device` option on tf.saved_model.LoadOptions to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   3928\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3929\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_def_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3930\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SentencepieceOp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[1;32m    890\u001b[0m                             ckpt_options, filters)\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, filters)\u001b[0m\n\u001b[1;32m    130\u001b[0m     self._concrete_functions = (\n\u001b[0;32m--> 131\u001b[0;31m         function_deserialization.load_function_def_library(\n\u001b[0m\u001b[1;32m    132\u001b[0m             meta_graph.graph_def.library))\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[0;34m(library, load_shared_name_suffix)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m       \u001b[0mfunc_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_def_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0m_restore_gradient_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenamed_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shapes_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   graph_def, nested_to_flat_tensor_name = function_def_to_graph_def(\n\u001b[0m\u001b[1;32m     59\u001b[0m       fdef, input_shapes)\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph_def\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   3932\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3933\u001b[0;31m         pywrap_tf_session.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type),\n\u001b[0m\u001b[1;32m   3934\u001b[0m                                            buf)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Op type not registered 'SentencepieceOp' in binary running on alones-MacBook-Pro.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-143e59f0da91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmax_mentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0m_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0m_hashtag_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtags_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0m_mention_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmentions_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[1;32m    105\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m   \"\"\"\n\u001b[0;32m--> 859\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    890\u001b[0m                             ckpt_options, filters)\n\u001b[1;32m    891\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         raise FileNotFoundError(\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n If trying to load on a different device from the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0;34m\"computational device, consider using setting the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Op type not registered 'SentencepieceOp' in binary running on alones-MacBook-Pro.local. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n If trying to load on a different device from the computational device, consider using setting the `experimental_io_device` option on tf.saved_model.LoadOptions to the io_device such as '/job:localhost'."
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 144;\n",
       "                var nbb_unformatted_code = \"import tensorflow as tf\\n\\nimport tensorflow_hub as hub\\n\\nfrom tensorflow.keras.layers import Embedding, Flatten\\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\\n\\n\\ndef embedding_model(vocab, max_len, max_features, out_dim):\\n    vectorize_layer = TextVectorization(\\n        max_tokens=max_features,\\n        output_sequence_length=max_len,\\n        output_mode=\\\"int\\\",\\n        # split=None,\\n        vocabulary=list(vocab),\\n    )\\n    return tf.keras.Sequential(\\n        layers=[vectorize_layer, Embedding(max_features + 1, out_dim), Flatten()]\\n    )\\n\\n\\nmax_hashtags = 5\\nmax_mentions = 5\\n\\n_embed = hub.load(\\\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\\\")\\n_hashtag_embed = embedding_model(hashtags_vocab, 8, 2000, 16)\\n_mention_embed = embedding_model(mentions_vocab, 8, 1500, 16)\";\n",
       "                var nbb_formatted_code = \"import tensorflow as tf\\n\\nimport tensorflow_hub as hub\\n\\nfrom tensorflow.keras.layers import Embedding, Flatten\\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\\n\\n\\ndef embedding_model(vocab, max_len, max_features, out_dim):\\n    vectorize_layer = TextVectorization(\\n        max_tokens=max_features,\\n        output_sequence_length=max_len,\\n        output_mode=\\\"int\\\",\\n        # split=None,\\n        vocabulary=list(vocab),\\n    )\\n    return tf.keras.Sequential(\\n        layers=[vectorize_layer, Embedding(max_features + 1, out_dim), Flatten()]\\n    )\\n\\n\\nmax_hashtags = 5\\nmax_mentions = 5\\n\\n_embed = hub.load(\\\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\\\")\\n_hashtag_embed = embedding_model(hashtags_vocab, 8, 2000, 16)\\n_mention_embed = embedding_model(mentions_vocab, 8, 1500, 16)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Flatten\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "\n",
    "def embedding_model(vocab, max_len, max_features, out_dim):\n",
    "    vectorize_layer = TextVectorization(\n",
    "        max_tokens=max_features,\n",
    "        output_sequence_length=max_len,\n",
    "        output_mode=\"int\",\n",
    "        # split=None,\n",
    "        vocabulary=list(vocab),\n",
    "    )\n",
    "    return tf.keras.Sequential(\n",
    "        layers=[vectorize_layer, Embedding(max_features + 1, out_dim), Flatten()]\n",
    "    )\n",
    "\n",
    "\n",
    "max_hashtags = 5\n",
    "max_mentions = 5\n",
    "\n",
    "_embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "_hashtag_embed = embedding_model(hashtags_vocab, 8, 2000, 16)\n",
    "_mention_embed = embedding_model(mentions_vocab, 8, 1500, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 128)\n",
      "(2, 128)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"print(_hashtag_embed.predict([[\\\"google apple\\\"], [\\\"app quote\\\"]]).shape)\\nprint(_mention_embed.predict([[\\\"google apple\\\"], [\\\"tesla\\\"]]).shape)\\n# print(_embed.predict(data.Tweet[10:15]).shape)\\n\\nembeddings = pd.DataFrame(\\n    {\\n        \\\"avis\\\": data.Avis.astype(\\\"category\\\").cat.codes,\\n        \\\"language\\\": data.Language.astype(\\\"category\\\").cat.codes,\\n    }\\n)\\n# embeddings.to_pickle(\\\"../data/embeddings.pkl\\\")\";\n",
       "                var nbb_formatted_code = \"print(_hashtag_embed.predict([[\\\"google apple\\\"], [\\\"app quote\\\"]]).shape)\\nprint(_mention_embed.predict([[\\\"google apple\\\"], [\\\"tesla\\\"]]).shape)\\n# print(_embed.predict(data.Tweet[10:15]).shape)\\n\\nembeddings = pd.DataFrame(\\n    {\\n        \\\"avis\\\": data.Avis.astype(\\\"category\\\").cat.codes,\\n        \\\"language\\\": data.Language.astype(\\\"category\\\").cat.codes,\\n    }\\n)\\n# embeddings.to_pickle(\\\"../data/embeddings.pkl\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(_hashtag_embed.predict([[\"google apple\"], [\"app quote\"]]).shape)\n",
    "print(_mention_embed.predict([[\"google apple\"], [\"tesla\"]]).shape)\n",
    "# print(_embed.predict(data.Tweet[10:15]).shape)\n",
    "\n",
    "embeddings = pd.DataFrame(\n",
    "    {\n",
    "        \"avis\": data.Avis.astype(\"category\").cat.codes,\n",
    "        \"language\": data.Language.astype(\"category\").cat.codes,\n",
    "    }\n",
    ")\n",
    "# embeddings.to_pickle(\"../data/embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0000    0\n",
       "0001    1\n",
       "0002    0\n",
       "0003    0\n",
       "0004    0\n",
       "       ..\n",
       "4168    0\n",
       "4169    0\n",
       "4170    0\n",
       "4171    0\n",
       "4172    0\n",
       "Name: Irr, Length: 4173, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 109;\n",
       "                var nbb_unformatted_code = \"data[\\\"Irr\\\"] = data.Avis.str.fullmatch(\\\"irr\\\").astype('int')\\ndata.Irr\";\n",
       "                var nbb_formatted_code = \"data[\\\"Irr\\\"] = data.Avis.str.fullmatch(\\\"irr\\\").astype(\\\"int\\\")\\ndata.Irr\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"Irr\"] = data.Avis.str.fullmatch(\"irr\").astype(\"int\")\n",
    "data.Irr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = np.hstack(\n",
    "    [\n",
    "        _embed(data.Tweet).numpy(),\n",
    "        _mention_embed.predict(data.Mentions.apply(lambda x: \" \".join(x))),\n",
    "        _hashtag_embed.predict(data.Hashtags.apply(lambda x: \" \".join(x))),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 133;\n",
       "                var nbb_unformatted_code = \"from thinc.api import (\\n    Model,\\n    chain,\\n    add,\\n    concatenate,\\n    clone,\\n    strings2arrays,\\n    array_getitem,\\n    with_array,\\n    Embed,\\n    HashEmbed,\\n    expand_window,\\n    Linear,\\n    Relu,\\n    Softmax,\\n    Dropout,\\n    Adam,\\n    warmup_linear,\\n    TensorFlowWrapper,\\n)\\nfrom thinc.types import List1d, Array2d\\nfrom thinc.util import to_categorical\";\n",
       "                var nbb_formatted_code = \"from thinc.api import (\\n    Model,\\n    chain,\\n    add,\\n    concatenate,\\n    clone,\\n    strings2arrays,\\n    array_getitem,\\n    with_array,\\n    Embed,\\n    HashEmbed,\\n    expand_window,\\n    Linear,\\n    Relu,\\n    Softmax,\\n    Dropout,\\n    Adam,\\n    warmup_linear,\\n    TensorFlowWrapper,\\n)\\nfrom thinc.types import List1d, Array2d\\nfrom thinc.util import to_categorical\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from thinc.api import (\n",
    "    Model,\n",
    "    chain,\n",
    "    add,\n",
    "    concatenate,\n",
    "    clone,\n",
    "    strings2arrays,\n",
    "    array_getitem,\n",
    "    with_array,\n",
    "    Embed,\n",
    "    HashEmbed,\n",
    "    expand_window,\n",
    "    Linear,\n",
    "    Relu,\n",
    "    Softmax,\n",
    "    Dropout,\n",
    "    Adam,\n",
    "    warmup_linear,\n",
    "    TensorFlowWrapper,\n",
    ")\n",
    "from thinc.types import List1d, Array2d\n",
    "from thinc.util import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 64\n",
    "dropout = 0.2\n",
    "\n",
    "\n",
    "def Hidden(n_hidden=10, dropout=0.2):\n",
    "    return chain(Relu(nO=n_hidden), Dropout(dropout))\n",
    "\n",
    "\n",
    "with Model.define_operators({\">>\": chain, \"|\": concatenate, \"+\": add, \"**\": clone}):\n",
    "    model = strings2arrays() >> Hidden(n_hidden, dropout) ** 2 >> Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.initialize(X=data.Hashtags.to_numpy(), Y=data.Avis.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Avis = data.Avis.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"from syntok.tokenizer import Tokenizer\\n\\n\\ndef tokenize_texts(texts):\\n    tok = Tokenizer()\\n    return [[token.value for token in tok.tokenize(text)] for text in texts]\\n\\n\\nimport ml_datasets\\nimport numpy\\n\\n\\ndef load_data():\\n    train_data, dev_data = ml_datasets.dbpedia(train_limit=2000, dev_limit=2000)\\n    train_texts, train_cats = zip(*train_data)\\n    dev_texts, dev_cats = zip(*dev_data)\\n    unique_cats = list(numpy.unique(numpy.concatenate((train_cats, dev_cats))))\\n    nr_class = len(unique_cats)\\n    print(f\\\"{len(train_data)} training / {len(dev_data)} dev\\\\n{nr_class} classes\\\")\\n\\n    train_y = numpy.zeros((len(train_cats), nr_class), dtype=\\\"f\\\")\\n    for i, cat in enumerate(train_cats):\\n        train_y[i][unique_cats.index(cat)] = 1\\n    dev_y = numpy.zeros((len(dev_cats), nr_class), dtype=\\\"f\\\")\\n    for i, cat in enumerate(dev_cats):\\n        dev_y[i][unique_cats.index(cat)] = 1\\n\\n    train_tokenized = tokenize_texts(train_texts)\\n    dev_tokenized = tokenize_texts(dev_texts)\\n    # Generate simple vocab mapping, <unk> is 0\\n    vocab = {}\\n    count_id = 1\\n    for text in train_tokenized:\\n        for token in text:\\n            if token not in vocab:\\n                vocab[token] = count_id\\n                count_id += 1\\n    # Map texts using vocab\\n    train_X = []\\n    for text in train_tokenized:\\n        train_X.append(numpy.array([vocab.get(t, 0) for t in text]))\\n    dev_X = []\\n    for text in dev_tokenized:\\n        dev_X.append(numpy.array([vocab.get(t, 0) for t in text]))\\n    return (train_X, train_y), (dev_X, dev_y), vocab\";\n",
       "                var nbb_formatted_code = \"from syntok.tokenizer import Tokenizer\\n\\n\\ndef tokenize_texts(texts):\\n    tok = Tokenizer()\\n    return [[token.value for token in tok.tokenize(text)] for text in texts]\\n\\n\\nimport ml_datasets\\nimport numpy\\n\\n\\ndef load_data():\\n    train_data, dev_data = ml_datasets.dbpedia(train_limit=2000, dev_limit=2000)\\n    train_texts, train_cats = zip(*train_data)\\n    dev_texts, dev_cats = zip(*dev_data)\\n    unique_cats = list(numpy.unique(numpy.concatenate((train_cats, dev_cats))))\\n    nr_class = len(unique_cats)\\n    print(f\\\"{len(train_data)} training / {len(dev_data)} dev\\\\n{nr_class} classes\\\")\\n\\n    train_y = numpy.zeros((len(train_cats), nr_class), dtype=\\\"f\\\")\\n    for i, cat in enumerate(train_cats):\\n        train_y[i][unique_cats.index(cat)] = 1\\n    dev_y = numpy.zeros((len(dev_cats), nr_class), dtype=\\\"f\\\")\\n    for i, cat in enumerate(dev_cats):\\n        dev_y[i][unique_cats.index(cat)] = 1\\n\\n    train_tokenized = tokenize_texts(train_texts)\\n    dev_tokenized = tokenize_texts(dev_texts)\\n    # Generate simple vocab mapping, <unk> is 0\\n    vocab = {}\\n    count_id = 1\\n    for text in train_tokenized:\\n        for token in text:\\n            if token not in vocab:\\n                vocab[token] = count_id\\n                count_id += 1\\n    # Map texts using vocab\\n    train_X = []\\n    for text in train_tokenized:\\n        train_X.append(numpy.array([vocab.get(t, 0) for t in text]))\\n    dev_X = []\\n    for text in dev_tokenized:\\n        dev_X.append(numpy.array([vocab.get(t, 0) for t in text]))\\n    return (train_X, train_y), (dev_X, dev_y), vocab\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from syntok.tokenizer import Tokenizer\n",
    "\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    tok = Tokenizer()\n",
    "    return [[token.value for token in tok.tokenize(text)] for text in texts]\n",
    "\n",
    "\n",
    "import ml_datasets\n",
    "import numpy\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_data, dev_data = ml_datasets.dbpedia(train_limit=2000, dev_limit=2000)\n",
    "    train_texts, train_cats = zip(*train_data)\n",
    "    dev_texts, dev_cats = zip(*dev_data)\n",
    "    unique_cats = list(numpy.unique(numpy.concatenate((train_cats, dev_cats))))\n",
    "    nr_class = len(unique_cats)\n",
    "    print(f\"{len(train_data)} training / {len(dev_data)} dev\\n{nr_class} classes\")\n",
    "\n",
    "    train_y = numpy.zeros((len(train_cats), nr_class), dtype=\"f\")\n",
    "    for i, cat in enumerate(train_cats):\n",
    "        train_y[i][unique_cats.index(cat)] = 1\n",
    "    dev_y = numpy.zeros((len(dev_cats), nr_class), dtype=\"f\")\n",
    "    for i, cat in enumerate(dev_cats):\n",
    "        dev_y[i][unique_cats.index(cat)] = 1\n",
    "\n",
    "    train_tokenized = tokenize_texts(train_texts)\n",
    "    dev_tokenized = tokenize_texts(dev_texts)\n",
    "    # Generate simple vocab mapping, <unk> is 0\n",
    "    vocab = {}\n",
    "    count_id = 1\n",
    "    for text in train_tokenized:\n",
    "        for token in text:\n",
    "            if token not in vocab:\n",
    "                vocab[token] = count_id\n",
    "                count_id += 1\n",
    "    # Map texts using vocab\n",
    "    train_X = []\n",
    "    for text in train_tokenized:\n",
    "        train_X.append(numpy.array([vocab.get(t, 0) for t in text]))\n",
    "    dev_X = []\n",
    "    for text in dev_tokenized:\n",
    "        dev_X.append(numpy.array([vocab.get(t, 0) for t in text]))\n",
    "    return (train_X, train_y), (dev_X, dev_y), vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 training / 2000 dev\n",
      "14 classes\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"(train_X, train_y), (dev_X, dev_y), vocab = load_data()\";\n",
       "                var nbb_formatted_code = \"(train_X, train_y), (dev_X, dev_y), vocab = load_data()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_X, train_y), (dev_X, dev_y), vocab = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 143;\n",
       "                var nbb_unformatted_code = \"len(train_X)\";\n",
       "                var nbb_formatted_code = \"len(train_X)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"from typing import List\\nimport thinc\\nfrom thinc.api import Model, chain, list2ragged, with_array, reduce_mean, Softmax\\nfrom thinc.types import Array2d\\n\\n\\n@thinc.registry.layers(\\\"EmbedPoolTextcat.v1\\\")\\ndef EmbedPoolTextcat(embed: Model[Array2d, Array2d]) -> Model[List[Array2d], Array2d]:\\n    with Model.define_operators({\\\">>\\\": chain}):\\n        model = with_array(embed) >> list2ragged() >> reduce_mean() >> Softmax()\\n    model.set_ref(\\\"embed\\\", embed)\\n    return model\";\n",
       "                var nbb_formatted_code = \"from typing import List\\nimport thinc\\nfrom thinc.api import Model, chain, list2ragged, with_array, reduce_mean, Softmax\\nfrom thinc.types import Array2d\\n\\n\\n@thinc.registry.layers(\\\"EmbedPoolTextcat.v1\\\")\\ndef EmbedPoolTextcat(embed: Model[Array2d, Array2d]) -> Model[List[Array2d], Array2d]:\\n    with Model.define_operators({\\\">>\\\": chain}):\\n        model = with_array(embed) >> list2ragged() >> reduce_mean() >> Softmax()\\n    model.set_ref(\\\"embed\\\", embed)\\n    return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "import thinc\n",
    "from thinc.api import Model, chain, list2ragged, with_array, reduce_mean, Softmax\n",
    "from thinc.types import Array2d\n",
    "\n",
    "\n",
    "@thinc.registry.layers(\"EmbedPoolTextcat.v1\")\n",
    "def EmbedPoolTextcat(embed: Model[Array2d, Array2d]) -> Model[List[Array2d], Array2d]:\n",
    "    with Model.define_operators({\">>\": chain}):\n",
    "        model = with_array(embed) >> list2ragged() >> reduce_mean() >> Softmax()\n",
    "    model.set_ref(\"embed\", embed)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"CONFIG = \\\"\\\"\\\"\\n[hyper_params]\\nwidth = 64\\n\\n[model]\\n@layers = \\\"EmbedPoolTextcat.v1\\\"\\n\\n[model.embed]\\n@layers = \\\"Embed.v1\\\"\\nnO = ${hyper_params:width}\\n\\n[optimizer]\\n@optimizers = \\\"Adam.v1\\\"\\nlearn_rate = 0.001\\n\\n[training]\\nbatch_size = 8\\nn_iter = 10\\n\\\"\\\"\\\"\";\n",
       "                var nbb_formatted_code = \"CONFIG = \\\"\\\"\\\"\\n[hyper_params]\\nwidth = 64\\n\\n[model]\\n@layers = \\\"EmbedPoolTextcat.v1\\\"\\n\\n[model.embed]\\n@layers = \\\"Embed.v1\\\"\\nnO = ${hyper_params:width}\\n\\n[optimizer]\\n@optimizers = \\\"Adam.v1\\\"\\nlearn_rate = 0.001\\n\\n[training]\\nbatch_size = 8\\nn_iter = 10\\n\\\"\\\"\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONFIG = \"\"\"\n",
    "[hyper_params]\n",
    "width = 64\n",
    "\n",
    "[model]\n",
    "@layers = \"EmbedPoolTextcat.v1\"\n",
    "\n",
    "[model.embed]\n",
    "@layers = \"Embed.v1\"\n",
    "nO = ${hyper_params:width}\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = 0.001\n",
    "\n",
    "[training]\n",
    "batch_size = 8\n",
    "n_iter = 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyper_params': {'width': 64},\n",
       " 'model': <thinc.model.Model at 0x15fca7140>,\n",
       " 'optimizer': <thinc.optimizers.Optimizer at 0x15dcbc860>,\n",
       " 'training': {'batch_size': 8, 'n_iter': 10}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"from thinc.api import registry, Config\\n\\nC = registry.resolve(Config().from_str(CONFIG))\\nC\";\n",
       "                var nbb_formatted_code = \"from thinc.api import registry, Config\\n\\nC = registry.resolve(Config().from_str(CONFIG))\\nC\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from thinc.api import registry, Config\n",
    "\n",
    "C = registry.resolve(Config().from_str(CONFIG))\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x15fca7140>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"batch_size = C[\\\"training\\\"][\\\"batch_size\\\"]\\noptimizer = C[\\\"optimizer\\\"]\\nmodel = C[\\\"model\\\"]\\nmodel.get_ref(\\\"embed\\\").set_dim(\\\"nV\\\", len(vocab) + 1)\\n\\nmodel.initialize(X=train_X, Y=train_y)\";\n",
       "                var nbb_formatted_code = \"batch_size = C[\\\"training\\\"][\\\"batch_size\\\"]\\noptimizer = C[\\\"optimizer\\\"]\\nmodel = C[\\\"model\\\"]\\nmodel.get_ref(\\\"embed\\\").set_dim(\\\"nV\\\", len(vocab) + 1)\\n\\nmodel.initialize(X=train_X, Y=train_y)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = C[\"training\"][\"batch_size\"]\n",
    "optimizer = C[\"optimizer\"]\n",
    "model = C[\"model\"]\n",
    "model.get_ref(\"embed\").set_dim(\"nV\", len(vocab) + 1)\n",
    "\n",
    "model.initialize(X=train_X, Y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 88;\n",
       "                var nbb_unformatted_code = \"def evaluate_model(model, dev_X, dev_Y, batch_size):\\n    correct = 0.0\\n    total = 0.0\\n    for X, Y in model.ops.multibatch(batch_size, dev_X, dev_Y):\\n        Yh = model.predict(X)\\n        for j in range(len(Yh)):\\n            correct += Yh[j].argmax(axis=0) == Y[j].argmax(axis=0)\\n        total += len(Y)\\n    return float(correct / total)\";\n",
       "                var nbb_formatted_code = \"def evaluate_model(model, dev_X, dev_Y, batch_size):\\n    correct = 0.0\\n    total = 0.0\\n    for X, Y in model.ops.multibatch(batch_size, dev_X, dev_Y):\\n        Yh = model.predict(X)\\n        for j in range(len(Yh)):\\n            correct += Yh[j].argmax(axis=0) == Y[j].argmax(axis=0)\\n        total += len(Y)\\n    return float(correct / total)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(model, dev_X, dev_Y, batch_size):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for X, Y in model.ops.multibatch(batch_size, dev_X, dev_Y):\n",
    "        Yh = model.predict(X)\n",
    "        for j in range(len(Yh)):\n",
    "            correct += Yh[j].argmax(axis=0) == Y[j].argmax(axis=0)\n",
    "        total += len(Y)\n",
    "    return float(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1838.10\t0.459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1617.94\t0.658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t1213.95\t0.808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\t833.20\t0.881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t527.36\t0.903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t322.09\t0.917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\t201.03\t0.927\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\t129.08\t0.926\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\t83.55\t0.928\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\t55.16\t0.931\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"from thinc.api import fix_random_seed\\nfrom tqdm.notebook import tqdm\\n\\nfix_random_seed(0)\\nfor n in range(C[\\\"training\\\"][\\\"n_iter\\\"]):\\n    loss = 0.0\\n    batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\\n    for X, Y in tqdm(batches, leave=False):\\n        Yh, backprop = model.begin_update(X)\\n        d_loss = []\\n        for i in range(len(Yh)):\\n            d_loss.append(Yh[i] - Y[i])\\n            loss += ((Yh[i] - Y[i]) ** 2).sum()\\n        backprop(numpy.array(d_loss))\\n        model.finish_update(optimizer)\\n    score = evaluate_model(model, dev_X, dev_y, batch_size)\\n    print(f\\\"{n}\\\\t{loss:.2f}\\\\t{score:.3f}\\\")\";\n",
       "                var nbb_formatted_code = \"from thinc.api import fix_random_seed\\nfrom tqdm.notebook import tqdm\\n\\nfix_random_seed(0)\\nfor n in range(C[\\\"training\\\"][\\\"n_iter\\\"]):\\n    loss = 0.0\\n    batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\\n    for X, Y in tqdm(batches, leave=False):\\n        Yh, backprop = model.begin_update(X)\\n        d_loss = []\\n        for i in range(len(Yh)):\\n            d_loss.append(Yh[i] - Y[i])\\n            loss += ((Yh[i] - Y[i]) ** 2).sum()\\n        backprop(numpy.array(d_loss))\\n        model.finish_update(optimizer)\\n    score = evaluate_model(model, dev_X, dev_y, batch_size)\\n    print(f\\\"{n}\\\\t{loss:.2f}\\\\t{score:.3f}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from thinc.api import fix_random_seed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "fix_random_seed(0)\n",
    "for n in range(C[\"training\"][\"n_iter\"]):\n",
    "    loss = 0.0\n",
    "    batches = model.ops.multibatch(batch_size, train_X, train_y, shuffle=True)\n",
    "    for X, Y in tqdm(batches, leave=False):\n",
    "        Yh, backprop = model.begin_update(X)\n",
    "        d_loss = []\n",
    "        for i in range(len(Yh)):\n",
    "            d_loss.append(Yh[i] - Y[i])\n",
    "            loss += ((Yh[i] - Y[i]) ** 2).sum()\n",
    "        backprop(numpy.array(d_loss))\n",
    "        model.finish_update(optimizer)\n",
    "    score = evaluate_model(model, dev_X, dev_y, batch_size)\n",
    "    print(f\"{n}\\t{loss:.2f}\\t{score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lengths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-ff8ed97b6f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefine_operators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\">>\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"|\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"+\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"**\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mRelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mvalidate_fwd_input_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(model, X, Y)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nO\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mvalidate_fwd_input_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(model, X, Y)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurr_input\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mcurr_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/extraction/venv/lib/python3.8/site-packages/thinc/layers/reduce_mean.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFloats2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lengths'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 141;\n",
       "                var nbb_unformatted_code = \"from thinc.api import (\\n    Model,\\n    chain,\\n    add,\\n    concatenate,\\n    clone,\\n    strings2arrays,\\n    array_getitem,\\n    residual,\\n    reduce_max,\\n    reduce_mean,\\n    with_array,\\n    Embed,\\n    HashEmbed,\\n    expand_window,\\n    Linear,\\n    Relu,\\n    Softmax,\\n    Dropout,\\n    Maxout,\\n    Adam,\\n    warmup_linear,\\n    TensorFlowWrapper,\\n)\\nfrom thinc.types import List1d, Array2d\\n\\n(x, y, dx, dy) = (\\n    tweets,\\n    to_categorical(embeddings.avis),\\n    tweets[3101:],\\n    to_categorical(embeddings.avis[3101:]),\\n)\\n\\nwith Model.define_operators({\\\">>\\\": chain, \\\"|\\\": concatenate, \\\"+\\\": add, \\\"**\\\": clone}):\\n    model = reduce_mean() >> (Linear() >> Relu() >> Dropout(0.5)) ** 2 >> Softmax()\\nmodel.initialize(X=x, Y=y)\\n\\nfor n in range(20):\\n    loss = 0.0\\n    batches = model.ops.multibatch(batch_size, x, y, shuffle=True)\\n    for X, Y in tqdm(batches, leave=False):\\n        Yh, backprop = model.begin_update(X)\\n        d_loss = []\\n        for i in range(len(Yh)):\\n            d_loss.append(Yh[i] - Y[i])\\n            loss += ((Yh[i] - Y[i]) ** 2).sum()\\n        backprop(numpy.array(d_loss))\\n        model.finish_update(optimizer)\\n    score = evaluate_model(model, dx, dy, batch_size)\\n    print(f\\\"{n}\\\\t{loss:.2f}\\\\t{score:.3f}\\\")\";\n",
       "                var nbb_formatted_code = \"from thinc.api import (\\n    Model,\\n    chain,\\n    add,\\n    concatenate,\\n    clone,\\n    strings2arrays,\\n    array_getitem,\\n    residual,\\n    reduce_max,\\n    reduce_mean,\\n    with_array,\\n    Embed,\\n    HashEmbed,\\n    expand_window,\\n    Linear,\\n    Relu,\\n    Softmax,\\n    Dropout,\\n    Maxout,\\n    Adam,\\n    warmup_linear,\\n    TensorFlowWrapper,\\n)\\nfrom thinc.types import List1d, Array2d\\n\\n(x, y, dx, dy) = (\\n    tweets,\\n    to_categorical(embeddings.avis),\\n    tweets[3101:],\\n    to_categorical(embeddings.avis[3101:]),\\n)\\n\\nwith Model.define_operators({\\\">>\\\": chain, \\\"|\\\": concatenate, \\\"+\\\": add, \\\"**\\\": clone}):\\n    model = reduce_mean() >> (Linear() >> Relu() >> Dropout(0.5)) ** 2 >> Softmax()\\nmodel.initialize(X=x, Y=y)\\n\\nfor n in range(20):\\n    loss = 0.0\\n    batches = model.ops.multibatch(batch_size, x, y, shuffle=True)\\n    for X, Y in tqdm(batches, leave=False):\\n        Yh, backprop = model.begin_update(X)\\n        d_loss = []\\n        for i in range(len(Yh)):\\n            d_loss.append(Yh[i] - Y[i])\\n            loss += ((Yh[i] - Y[i]) ** 2).sum()\\n        backprop(numpy.array(d_loss))\\n        model.finish_update(optimizer)\\n    score = evaluate_model(model, dx, dy, batch_size)\\n    print(f\\\"{n}\\\\t{loss:.2f}\\\\t{score:.3f}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from thinc.api import (\n",
    "    Model,\n",
    "    chain,\n",
    "    add,\n",
    "    concatenate,\n",
    "    clone,\n",
    "    strings2arrays,\n",
    "    array_getitem,\n",
    "    residual,\n",
    "    reduce_max,\n",
    "    reduce_mean,\n",
    "    with_array,\n",
    "    Embed,\n",
    "    HashEmbed,\n",
    "    expand_window,\n",
    "    Linear,\n",
    "    Relu,\n",
    "    Softmax,\n",
    "    Dropout,\n",
    "    Maxout,\n",
    "    Adam,\n",
    "    warmup_linear,\n",
    "    TensorFlowWrapper,\n",
    ")\n",
    "from thinc.types import List1d, Array2d\n",
    "\n",
    "(x, y, dx, dy) = (\n",
    "    tweets,\n",
    "    to_categorical(embeddings.avis),\n",
    "    tweets[3101:],\n",
    "    to_categorical(embeddings.avis[3101:]),\n",
    ")\n",
    "\n",
    "with Model.define_operators({\">>\": chain, \"|\": concatenate, \"+\": add, \"**\": clone}):\n",
    "    model = reduce_mean() >> (Linear() >> Relu() >> Dropout(0.5)) ** 2 >> Softmax()\n",
    "model.initialize(X=x, Y=y)\n",
    "\n",
    "for n in range(20):\n",
    "    loss = 0.0\n",
    "    batches = model.ops.multibatch(batch_size, x, y, shuffle=True)\n",
    "    for X, Y in tqdm(batches, leave=False):\n",
    "        Yh, backprop = model.begin_update(X)\n",
    "        d_loss = []\n",
    "        for i in range(len(Yh)):\n",
    "            d_loss.append(Yh[i] - Y[i])\n",
    "            loss += ((Yh[i] - Y[i]) ** 2).sum()\n",
    "        backprop(numpy.array(d_loss))\n",
    "        model.finish_update(optimizer)\n",
    "    score = evaluate_model(model, dx, dy, batch_size)\n",
    "    print(f\"{n}\\t{loss:.2f}\\t{score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173, 384)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 121;\n",
       "                var nbb_unformatted_code = \"tweets.shape\";\n",
       "                var nbb_formatted_code = \"tweets.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
