---
title: Rapport
authors: 
 - Oussama Bouzaouit
 - Jean-Marc Fares
date: 15/03/21
git-repo: https://github.com/al-one-zero/extraction
---

Extraction des donn√©es
===

0 - Introduction
---
Le probl√®me qui nous est propos√© est un probl√®me de traitement de la langue et d'analyse du sentiment d'un corpus de messages extraits du site de microblogging Twitter. On se propose de d√©terminer le sentiment que d√©crivent les tweets vis a vis d'une des entreprises suivantes : Google, Apple, Microsoft et Twitter.
On nous propose de discriminer les tweets en 4 cat√©gories : sentiment positif, n√©gatif, neutre et les tweets qui ne sont pas en rapport avec l'entreprise concern√©es.

Dans ce document, nous d√©crirons d'abord les donn√©es et l'adaptation que l'on en fait pour l'√©tude, les approches abord√©es et les r√©sultats que l'on obtient √† l'issue de l'approche choisie.

1 - Pr√©sentation des donn√©es et traitement pr√©alable
---
Les donn√©es se pr√©sentent dans un fichier texte par ensemble comportant un tweet par ligne. A chaque tweet sont associ√©s un indice, une √©tiquette de setiment parmis "pos", "neg", "neu" et "irr" respectivement pour designer les sentiments positif, n√©gatif, neutre et sans rapport, et une √©tiquette d√©signant l'entreprise concern√©e par le tweet. Un extrait des donn√©es est fourni en Figure 1.

```
(0000,neu,apl) 20 min line @apple store @short pump.
(0001,irr,msf) Nueva tecnolog√≠a convierte cualquier superficie en una pantalla multitactil. http://t.co/EDibLL5V #Microsoft #omnitouch
(0002,neu,ggl) Some people should not post replies in #Google+ threads. Their posts only continue to weaken their creditbility.
(0003,neg,apl) I know a few others having same issue RT @Joelplane: 9% now on my second full charge of the day. Pissed @Apple
(0004,neg,msf) #Microsoft - We put the ""backwards"" into backwards compatibility. #instantfollowback
(0005,neg,twt) #twitter is sooo trash ritenow with all dezz #highscoolmemories -__-
(0006,neu,apl) RT @jesperordrup: Hi @apple. Household has 4 iphones, 2 ipads, 2 minis, 2 apple tv, AirPorts, Timecapsule +. Whats a usable iPhoto shari ...
(0007,irr,msf) #ALG Culminando formaci√≥n en #Microsoft M-2778 y en #IndicadoresDeGesti√≥n. Gracias a nuestros clientes por su preferencia. www.alg.net.ve
(0008,neu,msf) #Microsoft Community Blogs The 7/365 Review - The Cloud's Impact on Business http://t.co/gPB2MjFW
(0009,irr,twt) Buenas noches a todos #Twitter off
```
_Fig. 1 :_ Extrait du corpus d'entrainement des tweets

Nous importons ce fichier dans un environnement `python` √† l'aide de la biblioth√®que [`pandas`](http://pandas.pydata.org).

### Extraction des _mentions_ et des _hashtags_ [[source]](https://github.com/al-one-zero/extraction/blob/2b1308c63e731643da9f3b4c6b174716c13e6873/extraction/preprocessing.py#L54)

Un premier traitement que nous r√©alisons est celui d'extraire les hashtags et les mentions contenues dans chaque tweet. Nous remplacons les mots de ces deux types de lien propre √† twitter par leur contenu textuel : "#microsoft" devient "microsoft" et "@apple" devient "apple" par exemple. Nous pla√ßons ensuite toutes les mentions dans une liste que l'on ajoute √† la ligne du tweet concern√©, de m√™me pour les mentions.

### Remplacement des √©mojis [[source]](https://github.com/al-one-zero/extraction/blob/2b1308c63e731643da9f3b4c6b174716c13e6873/extraction/preprocessing.py#L31)

De plus, pour rendre compte de l'information contenue dans les √©mojis, on d√©cide de les remplacer par leur nom unicode (le nom sous lequel ils sont d√©crits dans la norme les introduisant).  
Ainsi, l'√©moji "ü•ì" ayant pour texte unicode "\:bacon:" devient le mot "bacon", ou bien "ü§ô" ayant pour texte  "\:call_me_hand:" devient "call me hand".

### Liens hypertexte [[source]](https://github.com/al-one-zero/extraction/blob/2b1308c63e731643da9f3b4c6b174716c13e6873/extraction/preprocessing.py#L20)

Les liens hypertexte (c'est-√†-dire les cha√Ænes de caract√®res pr√©fix√©es par "http(s)://bit.ly" - car twitter raccourcit automatiquement les liens avec le raccourcisseur _bit.ly_) sont remplac√©s par la cha√Æne "\_LINK_".

## 2 - M√©thodologie de pr√©diction du sentiment

### a) D√©tection de la langue du tweet [[source]](https://github.com/al-one-zero/extraction/blob/2b1308c63e731643da9f3b4c6b174716c13e6873/extraction/preprocessing.py#L87)

On constate qu'une grande majorit√© des tweets de la classe "irr" sont formul√©s dans une langue autre que l'anglais. Forts de ce constat, on se propose d'ajouter une information sur la langue de chaque tweet.  
Pour automatiser le processus, on utilise un mod√®le pr√©entrain√© de la librairie [`fasttext`](https://fasttext.cc/docs/en/language-identification.html). Ce module permet d'identifier 176 langues et est entrain√© sur les corpus de texte de Wikip√©dia, de SETimes et du corpus de traduction collaboratif Tatoeba.  
En pratique, on interroge le mod√®le pour chaque tweet, et l'on ajoute le bigramme correspondant au tweet - dans une nouvelle colonne, ainsi que la probabilit√© avec laquelle le tweet est formul√© dans la langue cit√©e.

### b) Plongements de texte

Afin de pouvoir pr√©senter le contenu des donn√©es √† un pr√©dicteur, nous pouvons utiliser des plongements de texte pour transformer le contenu textuel du tweet en une repr√©sentation num√©rique.  
Parmis les options qui s'offrent √† nous, on choisit d'uiliser des r√©seaux d'embedding pr√©entrain√©s sur des corpus de texte plus imposants que le notre. Pour cette seconde option, on se propose d'essayer les embeddings [nnlm](https://tfhub.dev/google/nnlm-en-dim128/2) et [BERT](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3).

En pratique, l'utilisation des deux types de mod√®les sont √©quivalents autant dans la mise en place de la solution que dans les r√©sultats.
Pour produire une repr√©sentation vectorielle de nos tweets, il nous faut t√©l√©charger le mod√®le pr√©entrain√© depuis internet et le charger √† l'aide respectivement des modules `tensorflow_hub` et `tensorflow`.  
La marche √† suivre est donn√©e sur la page de chacun des mod√®les sur [tfhub.dev](https://tfhub.dev). Une l√©g√®re subtilit√© est que BERT n'attend pas une cha√Æne de caract√®res en entr√©e, le tweet doit √™tre tokenis√© (d√©coupage de la cha√Æne de catract√®res initiale en liste de mots). Le pr√©processeur produit pour chaque tweet le triplet de tenseurs entiers suivants : un tenseur des indices des mots utilis√©s, un tenseur repr√©sentant le masque que l'on a sur le tenseur pr√©c√©dent (afin que tous les tweets aient la m√™me longueur, on remplit les tweets les plus courts pour qu'ils aient la m√™me longueur que le plus long), puis un tenseur des d√©buts des tokens dans le tweet. Le mod√®le `nnlm` luiu attent directement des cha√Ænes de caract√®re, donc il n'y a pas de pr√©processing √† faire en amont.  

### c) Entreprise et langue

Nous incluons l'information sur le nom de l'entreprise que concerne le tweet. Au m√™me titre que pour l'information de langue, il nous faut les transformer en donn√©e num√©rique. On choisit simplement de transformer les deux variables en variables cat√©gorielles, on remplace les chaines de caract√®re par les indices desdites variables, ces indices nous les transformons par la suite en vecteurs one-hot.  

### d) Predicteur

Nous choisissons d'utiliser un r√©seau de neurones profonds avec quatre couches cach√©es :
  - une couche cach√©e pour chacune des colonnes "Language" et "Entreprise" de 4 neuronnes,
  - deux couche cach√©es communes de 128 et 64 neuronnes plac√©es apr√®s la couche de concat√©nation des trois entr√©es, suivies chacune d'une couche _dropout_ - elle est responsable de l'introduction d'un bruit, qui permet de r√©duire l'impact du surapprentissage.  

Nous utilisons `tensorflow.keras` pour impl√©menter cette m√©thode d'apprentissage. Une vision sch√©matique de ce r√©seau de neuronnes est en Figure 2.
![Schematisation du mod√®le](https://i.imgur.com/ADB8Dfs.png)
_Fig. 2:_ Sch√©matisation du mod√®le


Nous pouvons enfin formuler la remarque suivante : afin de combatre d'autant plus efficaceement le ph√©nom√®ne de sur apprentissage, on ajoute de la r√©gularisation L1 sur les poids internes et de la r√©gularisation L2 sur les sorties de nos couches cach√©es.

## 3 - R√©sultats

Pour entrainer nos mod√®les, nous avons s√©par√© le jeu initial fourni dans le fichier `train.txt` en trois sous-ensembles : train, validation (√† la vol√©e pendant l'entrainement) et test.  

Il est essentiel de remarquer que l'on a effectu√© les entrainements de nos mod√®les √† l'aide d'une machine exploitant une acc√©l√©ration graphique. Chaque √©poque demandant environ une minute d'execution. Sur une machine personnelle, cela varie et est de l'ordre de la dizaine de minutes.  

En moyenne, le mod√®le converge assez rapidement, il lui faut entre 2 et 3 √©poques pour atteindre les 85% d'acquit√© sur le jeu de donn√©es de validation. On atteint dans les meilleurs cas plus de 90% (r√©guli√®rement 93%) de bonnes r√©ponses.
De m√™me sur le jeu de test, sur lequel nous obtennons des r√©sultats comparables.  

Pour ce qui est de l'ensemble des donn√©es de v√©rification, nous obtenons la r√©partition en sentiments suivante : 
```
neu    490
irr    303
neg    133
pos     74
```

## 4 - Conclusion

